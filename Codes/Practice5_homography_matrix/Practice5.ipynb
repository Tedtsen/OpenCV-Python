{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 225, 3) uint8\n",
      "(335, 295, 3)\n"
     ]
    }
   ],
   "source": [
    "#translation\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('sakura.jpg')\n",
    "num_rows, num_cols = img.shape[:2] #choose first two data\n",
    "print(img.shape, img.dtype)\n",
    "\n",
    "#image translation using translation_matrix\n",
    "translation_matrix = np.float32([ [0.2, 0.5,  70], \n",
    "                                  [0.5, 0.2, 110] ])\n",
    "\n",
    "img_translation1 = cv2.warpAffine(img, translation_matrix, (num_cols+70, num_rows+110), cv2.INTER_LINEAR)\n",
    "#cv2.warpAffine(src, M(2*3 mat), dsize[, dst[, flags[, borderMode[, borderValue]]]]) â†’ dst\n",
    "\n",
    "#image translation using ROI\n",
    "img_translation2 = np.zeros((num_rows+110, num_cols+70, 3), dtype=np.uint8) \n",
    "print(img_translation2.shape)\n",
    "img_translation2[110:num_rows+110, 70:num_cols+70, :] = img\n",
    "\n",
    "cv2.imshow('Translation1', img_translation1)\n",
    "cv2.imshow('Translation2', img_translation2)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.60621778  0.35        4.92549945]\n",
      " [-0.35        0.60621778 83.67549945]]\n"
     ]
    }
   ],
   "source": [
    "#rotation\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "img = cv2.imread('sakura.jpg')\n",
    "num_rows, num_cols = img.shape[:2]\n",
    "rotation_matrix = cv2.getRotationMatrix2D((num_cols/2, num_rows/2), #centrePt\n",
    "                                          30, #rotationDeg ClockWise\n",
    "                                          0.7) #resizeRatio\n",
    "print(rotation_matrix)\n",
    "img_rotation = cv2.warpAffine(img, rotation_matrix, (num_cols, num_rows))\n",
    "cv2.imshow('Rotation', img_rotation)\n",
    "cv2.imshow('Original', img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "#http://paulbourke.net/miscellaneous/interpolation/\n",
    "\n",
    "import cv2\n",
    "img = cv2.imread('sakura.jpg')\n",
    "img_scaled = cv2.resize(img,None,fx=1.5, fy=1.5, interpolation = cv2.INTER_LINEAR)\n",
    "cv2.imshow('Scaling - Linear Interpolation', img_scaled)\n",
    "img_scaled = cv2.resize(img,None,fx=1.5, fy=1.5, interpolation = cv2.INTER_CUBIC)\n",
    "cv2.imshow('Scaling - Cubic Interpolation', img_scaled)\n",
    "\n",
    "#specify new (col, row) in opencv, but in np (col, row)\n",
    "img_scaled = cv2.resize(img,(600, 400), interpolation = cv2.INTER_AREA)\n",
    "cv2.imshow('Scaling - Skewed Size', img_scaled)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perspective transformation\n",
    "#Practice\n",
    "import cv2\n",
    "import numpy as np\n",
    "wall = cv2.imread('tile_texture_4.jpg')\n",
    "floor = cv2.imread('peekaboo.png')\n",
    "rows, cols = wall.shape[:2]\n",
    "frows, fcols = floor.shape[:2]\n",
    "newRows, newCols = 640, 640\n",
    "\n",
    "#in numpy, specify in the order of col, row\n",
    "#North\n",
    "src_points = np.float32([[0     ,      0], \n",
    "                         [cols-1,      0], \n",
    "                         [0     , rows-1], \n",
    "                         [cols-1, rows-1]])\n",
    "\n",
    "Ndst_points = np.float32([[0       ,   0], \n",
    "                         [newCols-1,   0], \n",
    "                         [220      , 220], \n",
    "                         [420      , 220]])\n",
    "\n",
    "#South\n",
    "Sdst_points = np.float32([[220      ,       420], \n",
    "                          [420      ,       420],\n",
    "                          [0       , newRows-1], \n",
    "                          [newCols-1, newRows-1]])\n",
    "\n",
    "#East\n",
    "Edst_points = np.float32([[0  ,         0], \n",
    "                          [0  , newRows-1], \n",
    "                          [220,       220], \n",
    "                          [220,       420]])\n",
    "\n",
    "#West\n",
    "Wdst_points = np.float32([[420     ,       220], \n",
    "                         [newCols-1,         0], \n",
    "                         [420      ,       420], \n",
    "                         [newCols-1, newRows-1]])\n",
    "\n",
    "#Floor\n",
    "fsrc_points = np.float32([[0      ,       0], \n",
    "                          [fcols-1,       0], \n",
    "                          [0      , frows-1], \n",
    "                          [fcols-1, frows-1]])\n",
    "\n",
    "fdst_points = np.float32([[221       ,   221], \n",
    "                          [419,   221], \n",
    "                          [221      , 419], \n",
    "                          [419      , 419]])\n",
    "\n",
    "#cv2.findHomography() can accept more than 4 pairs of corresponding points\n",
    "Nprojective_matrix = cv2.getPerspectiveTransform(src_points, Ndst_points)\n",
    "Sprojective_matrix = cv2.getPerspectiveTransform(src_points, Sdst_points)\n",
    "Eprojective_matrix = cv2.getPerspectiveTransform(src_points, Edst_points)\n",
    "Wprojective_matrix = cv2.getPerspectiveTransform(src_points, Wdst_points)\n",
    "fprojective_matrix = cv2.getPerspectiveTransform(fsrc_points, fdst_points)\n",
    "\n",
    "Nwall = cv2.warpPerspective(wall, Nprojective_matrix, (640,640))\n",
    "Swall = cv2.warpPerspective(wall, Sprojective_matrix, (640,640))\n",
    "Ewall = cv2.warpPerspective(wall, Eprojective_matrix, (640,640))\n",
    "Wwall = cv2.warpPerspective(wall, Wprojective_matrix, (640,640))\n",
    "floor = cv2.warpPerspective(floor, fprojective_matrix, (640,640))\n",
    "\n",
    "temp1 = cv2.add(Nwall, Swall)\n",
    "temp2 = cv2.add(Ewall, Wwall)\n",
    "walls = cv2.add(temp1, temp2)\n",
    "room = cv2.add(walls, floor)\n",
    "\n",
    "ret, masked_room = cv2.threshold(room, 150, 0, cv2.THRESH_TOZERO)\n",
    "\n",
    "rec_mask = np.zeros_like(masked_room)\n",
    "rec_mask[:,:,:] = 255\n",
    "cv2.rectangle(rec_mask, (220, 220), (420, 420), (0, 255, 255), 15)\n",
    "masked_room = cv2.bitwise_and(masked_room, rec_mask)\n",
    "\n",
    "cv2.imshow('Output', room)\n",
    "cv2.imshow('Masked Output', masked_room)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
