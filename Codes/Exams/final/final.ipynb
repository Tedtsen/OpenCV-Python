{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'please choose suitable template for optimal result'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solve wiiplay find mii game_1 : \"find_this_mii\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "scaling_factor = 1\n",
    "cap = cv2.VideoCapture(\"wiiplay.mp4\")\n",
    "frame_seq = 4820\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "_, first_frame = cap.read()\n",
    "first_frame = cv2.resize(first_frame, None, fx=0.8, fy=0.8, interpolation=cv2.INTER_AREA)\n",
    "bbox = cv2.selectROI(first_frame, False, False)\n",
    "cv2.destroyAllWindows()\n",
    "x, y, w, h = bbox\n",
    "template = np.copy(first_frame[y:y+h, x:x+w])\n",
    "\n",
    "while True:\n",
    "    frame_seq += 1\n",
    "    if frame_seq > 5000:\n",
    "        frame_seq = 4820\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "    status_cap, frame0 = cap.read()\n",
    "    if not status_cap:\n",
    "        break\n",
    "    frame = cv2.resize(frame0, None, fx=scaling_factor, fy=scaling_factor)\n",
    "    \n",
    "    # Do simple template matching\n",
    "    result = cv2.matchTemplate(frame, template, cv2.TM_CCOEFF_NORMED)\n",
    "    result = cv2.normalize(result, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(result)\n",
    "    \n",
    "    cv2.rectangle(frame, (maxLoc[0], maxLoc[1]), \n",
    "                (maxLoc[0] + int(w), maxLoc[1] + int(h)),(0, 0, 255), 3)\n",
    "    \n",
    "    cv2.imshow(\"find_this_mii\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''please choose suitable template for optimal result'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reminder: requires haarcascade_frontalface_default.xml'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solve wiiplay find mii game_2 : \"find_two_look_alike\"\n",
    "#requires haarcascade_frontalface_default.xml\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "scaling_factor = 1\n",
    "cap = cv2.VideoCapture(\"wiiplay.mp4\")\n",
    "frame_seq = 2180\n",
    "\n",
    "# Using HOG for pedestrian detection\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "\n",
    "# Using haarcascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "final_template = None\n",
    "max_similarity = -1\n",
    "templates = list()\n",
    "\n",
    "while True:\n",
    "    frame_seq += 1\n",
    "    if frame_seq > 2380:\n",
    "        frame_seq = 2180\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "    status_cap, frame0 = cap.read()\n",
    "    if not status_cap:\n",
    "        break\n",
    "    frame = cv2.resize(frame0, None, fx=0.75, fy=0.75)\n",
    "    final_frame = frame.copy()\n",
    "    \n",
    "    # Draw pedestrian\n",
    "    locations, weights = hog.detectMultiScale(frame, finalThreshold = 2)\n",
    "    for loc in locations:   \n",
    "        cv2.rectangle(final_frame, (loc[0], loc[1]-50),(loc[0]+loc[2], loc[1]+loc[3]), (0, 255, 0), 3)\n",
    "    \n",
    "    # Face detection\n",
    "    face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.5, minNeighbors=1)\n",
    "    # Draw face (strict criteria) in dark blue and append face templates\n",
    "    for (x,y,w,h) in face_rects:\n",
    "        hsv_face = cv2.cvtColor(frame[y+5:y-10+h, x+5:x-10+w], cv2.COLOR_BGR2HSV)\n",
    "        # Check hsv of detected faces, if pass then put into templates list\n",
    "        if (np.mean(hsv_face[:,:,0])>=0 and np.mean(hsv_face[:,:,0])<=35):\n",
    "            if (np.mean(hsv_face[:,:,1])>=50 and np.mean(hsv_face[:,:,1])<=200):\n",
    "                if (np.mean(hsv_face[:,:,2])>=60 and np.mean(hsv_face[:,:,2])<=235): \n",
    "                    templates.append(frame[y+5:y-10+h, x+5:x-10+w])\n",
    "                    cv2.rectangle(final_frame, (x-5,y-5), (x+w+5,y+h+5), (255,0,0), 3)\n",
    "    # Draw face (weak criteria) in light blue\n",
    "    face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.05, minNeighbors=3)\n",
    "    for (x,y,w,h) in face_rects:\n",
    "        cv2.rectangle(final_frame, (x-5,y-5), (x+w+5,y+h+5), (255,128,0), 3)\n",
    "\n",
    "        \n",
    "    index = 0\n",
    "    for temp in templates:\n",
    "        result = cv2.matchTemplate(frame, temp, cv2.TM_CCOEFF_NORMED)\n",
    "        result = cv2.normalize(result, None, 0, 1, cv2.NORM_MINMAX)\n",
    "        minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(result)\n",
    "        # Highest similarity template is put to final_template\n",
    "        if (maxVal >= max_similarity) and maxVal > 0.99:\n",
    "            final_template = temp.copy()\n",
    "            templates[index] = temp\n",
    "            index+=1\n",
    "    # Only keep first 3 templates in front of the list (top 3 highest similarity)\n",
    "    del templates[3:]\n",
    "    \n",
    "    # Draw similar faces using final_template template matching\n",
    "    if (templates):\n",
    "        result = cv2.matchTemplate(frame, final_template, cv2.TM_CCOEFF_NORMED)\n",
    "        result = cv2.normalize(result, None, 0, 1, cv2.NORM_MINMAX)\n",
    "        minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(result)\n",
    "        result2 = np.reshape(result, result.shape[0]*result.shape[1])\n",
    "        sort = np.argsort(result2)[::-1]\n",
    "        (y1, x1) = np.unravel_index(sort[0], result.shape) # best match\n",
    "        for i in range (len(sort)):\n",
    "            (y, x) = np.unravel_index(sort[i], result.shape)\n",
    "            if (abs(y-y1)>10 and abs(x-x1)>10): # if position of second best match is 25 pxs away (no overlapping)\n",
    "                (y2, x2) = np.unravel_index(sort[i], result.shape) # second best match\n",
    "                break\n",
    "        cv2.rectangle(final_frame, (x1-5, y1-5), (x1 + int(w)-5, y1 + int(h)-5),(0, 0, 255), 3)\n",
    "        cv2.rectangle(final_frame, (x2-5, y2-5), (x2 + int(w)-5, y2 + int(h)-5),(0, 0, 255), 3)\n",
    "    \n",
    "    # Additional show current template being used to find similar faces\n",
    "    if (templates): \n",
    "        final_template = cv2.resize(final_template, (256, 256), fx=1, fy=1)\n",
    "        cv2.imshow('Looking for', final_template)\n",
    "    cv2.imshow(\"find_two_look_alike\", final_frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''reminder: requires haarcascade_frontalface_default.xml'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reminder: pip install opencv-contrib-python --user'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solve wiiplay find mii game_3 : \"find_the_fastest_character\"\n",
    "# pip install opencv-contrib-python --user\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "scaling_factor = 1\n",
    "cap = cv2.VideoCapture(\"wiiplay.mp4\")\n",
    "frame_seq = 2480\n",
    "\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "_, first_frame = cap.read()\n",
    "\n",
    "# Using HOG for pedestrian detection\n",
    "hog = cv2.HOGDescriptor()\n",
    "hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "locations, weights = hog.detectMultiScale(first_frame, hitThreshold = 0.1, winStride=(5,10)\n",
    "                                          ,finalThreshold = 1)\n",
    "\n",
    "# Create bbox for each detected pedestrian\n",
    "prev_pos = list()\n",
    "bboxes = list()\n",
    "for loc in locations:    \n",
    "    cv2.rectangle(first_frame, (loc[0], loc[1]),\n",
    "                  (loc[0]+loc[2], loc[1]+loc[3]), (255, 0, 0), 3)\n",
    "    #bboxes.append((loc[0]+30, loc[1]+30,loc[2]-40, loc[3]-40))\n",
    "    bboxes.append((loc[0]+int(loc[2]/3), loc[1]+int(loc[3]/4), int(loc[2]/3), int(loc[3]/7)))\n",
    "    prev_pos.append((loc[0], loc[1]))\n",
    "cv2.imshow('first frame', first_frame)\n",
    "cv2.waitKey()\n",
    "\n",
    "# Use median flow to track each bbox\n",
    "status_trackers = list()\n",
    "trackers = list()\n",
    "for bbox in bboxes:\n",
    "    trackers.append(cv2.TrackerMedianFlow_create())\n",
    "for i in range(len(trackers)):\n",
    "    status_trackers.append(trackers[i].init(first_frame, bboxes[i]))\n",
    "\n",
    "while True:\n",
    "    frame_seq += 1\n",
    "    if frame_seq > 2600:\n",
    "        frame_seq = 2480\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "    status_cap, frame0 = cap.read()\n",
    "    if not status_cap:\n",
    "        break\n",
    "    frame = cv2.resize(frame0, None, fx=scaling_factor, fy=scaling_factor)\n",
    "    \n",
    "    max_pos_diff = -1\n",
    "    # Update each bbox tracker and find maximum position difference\n",
    "    for i in range (len(status_trackers)):\n",
    "        if status_trackers[i]:\n",
    "            status_trackers[i], bboxes[i] = trackers[i].update(frame)\n",
    "        if status_trackers[i]:\n",
    "            x, y, w, h = [int(k) for k in bboxes[i]]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "            if (abs(x-prev_pos[i][0])+abs(y-prev_pos[i][1])>max_pos_diff):\n",
    "                max_pos = prev_pos[i]\n",
    "            prev_pos[i] = (x, y)\n",
    "\n",
    "    # Draw red rectangle on tracker with maximum position difference between frames\n",
    "    cv2.rectangle(frame, (max_pos[0], max_pos[1]), (max_pos[0]+100, max_pos[1]+100), (0,0,255), 3)\n",
    "    cv2.imshow(\"find_the_fastest_character\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''please press Enter or any key to continue after first frame'''\n",
    "'''reminder: pip install opencv-contrib-python --user'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Odd mii detection happens a while later, please wait for a moment'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solve wiiplay find mii game_4 : \"find_two_odds\"\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "scaling_factor = 1\n",
    "cap = cv2.VideoCapture(\"wiiplay.mp4\")\n",
    "frame_seq = 1650\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "_ , prev_frame = cap.read()\n",
    "prev_frame = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)\n",
    "prev_frame = cv2.resize(prev_frame, (0,0), None, fx=scaling_factor, fy=scaling_factor)\n",
    "first_frame = True\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def display_flow(img, flow, stride=10):\n",
    "    left = 0\n",
    "    right = 0\n",
    "    for index in np.ndindex(flow[::stride, ::stride].shape[:2]):\n",
    "        pt1 = tuple(i*stride for i in index)\n",
    "        delta = flow[pt1].astype(np.int32)[::-1]\n",
    "        pt2 = tuple(pt1 + 2*delta)\n",
    "        \n",
    "        if 2 <= cv2.norm(delta) <= 10:\n",
    "            cv2.arrowedLine(img, pt1[::-1], pt2[::-1], (255,0,0), 1, cv2.LINE_AA, 0, 0.1)\n",
    "        if (pt1[1]-pt2[1])>0: # Sum of left arrows\n",
    "            left += 1\n",
    "        elif (pt2[1]-pt1[1])>0: # Sum of right arrows\n",
    "            right += 1\n",
    "            \n",
    "    # Get positions of faces that have odd arrows\n",
    "    face_rects = face_cascade.detectMultiScale(frame, scaleFactor=1.1, minNeighbors=3)\n",
    "    # Add a new column in face_rects for voting\n",
    "    N = len(face_rects)\n",
    "    face_rects = np.c_[face_rects, np.zeros(N)]\n",
    "    face_rects = face_rects.astype(int)\n",
    "    for index in np.ndindex(flow[::stride, ::stride].shape[:2]):\n",
    "        pt1 = tuple(i*stride for i in index)\n",
    "        delta = flow[pt1].astype(np.int32)[::-1]\n",
    "        pt2 = tuple(pt1 + 2*delta)\n",
    "        for index, (x,y,w,h,votes) in enumerate(face_rects):\n",
    "            if (left>right) and (left+right)>500 and pt2[1]-pt1[1]>0 and (pt2[1]>x and pt2[1]<x+w) and (pt2[0]>y and pt2[0]<y+h):\n",
    "                face_rects[index,4]+=1\n",
    "                break\n",
    "            elif (right>left) and (left+right)>500 and (pt1[1]-pt2[1])>0 and (pt1[1]>x and pt1[1]<x+w) and (pt1[0]>y and pt1[0]<y+h):\n",
    "                face_rects[index,4]+=1\n",
    "                break\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h), (255,0,0), 3)\n",
    "    for (x,y,w,h,votes) in face_rects:\n",
    "        if (votes > 5):\n",
    "            cv2.rectangle(frame, (x,y), (x+w,y+h), (0,0,255), 3)\n",
    "    #norm_opt_flow = np.linalg.norm(flow, axis=2)\n",
    "    #norm_opt_flow = cv2.normalize(norm_opt_flow, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    #cv2.imshow('optical flow', img)\n",
    "    #cv2.imshow('optical flow magnitude', norm_opt_flow)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "bboxes = list()\n",
    "while True:\n",
    "    frame_seq += 1\n",
    "    if frame_seq > 1800:\n",
    "        frame_seq = 1650\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES , frame_seq)\n",
    "    status_cap, frame0 = cap.read()\n",
    "    if not status_cap:\n",
    "        break\n",
    "    frame = cv2.resize(frame0, None, fx=scaling_factor, fy=scaling_factor)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    if first_frame:\n",
    "        opt_flow = cv2.calcOpticalFlowFarneback(prev_frame, gray, None, 0.5, 5, 13, 10, 5, 1.1, cv2.OPTFLOW_FARNEBACK_GAUSSIAN)\n",
    "        first_frame = False\n",
    "    else:\n",
    "        opt_flow= cv2.calcOpticalFlowFarneback(prev_frame, gray, opt_flow, 0.5, 5, 13, 10, 5, 1.1, cv2.OPTFLOW_USE_INITIAL_FLOW)\n",
    "    prev_frame = np.copy(gray)\n",
    "\n",
    "    if display_flow(frame, opt_flow):\n",
    "        break;\n",
    "\n",
    "    cv2.imshow(\"find_two_odds\", frame)\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == 27:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "'''Movement too small hard to detect'''\n",
    "'''Mouse moving around, interfere flow result'''\n",
    "'''Odd mii detection happens a while later, please wait for a moment'''\n",
    "'''reminder: requires haarcascade_frontalface_default.xml'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### %%writefile test\n",
    "## Final Exam\n",
    "<b>The general objective is to solve four different games to find mii.<br>\n",
    "The code for each game should be written in an individual cell.<br>\n",
    "Add comments in your code to explain your approach.<br>\n",
    "You can design your own approach, and use any method you learned in this class.</b><br>\n",
    "\n",
    "1A. Input images from video file WiiPlay.mp4 with level 15 (frame number between 4820 and 5000).<br> \n",
    "1B. (10pts) Acquire a <b>face template</b> from the first frame (frame number = 4820).<br>\n",
    "1C. (10pts) Try to detect the face the same as the template on subsequent frames, draw a <b>red</b> rectangle around the detected face, and show the output images in the <b>\"find_this_mii\"</b> window.<br><br>\n",
    "\n",
    "2A. Input images from video file WiiPlay.mp4 with level 8 (frame number between 2180 and 2380).<br>\n",
    "2B. (10pts) Detect <b>pedestrians</b> on each frame and draw a <b>green</b> rectangle around your detection.<br>\n",
    "2C. (10pts) Detect <b>faces</b> on each frame and draw a <b>blue</b> rectangle around your detection.<br>\n",
    "2D. (10pts) Try to find two faces look alike each other, draw a <b>red</b> rectangle around each of the two faces, and show the output images in the <b>\"find_two_look_alike\"</b> window.<br><br>\n",
    "\n",
    "3A. Input images from video file WiiPlay.mp4 with level 9 (frame number between 2480 and 2600).<br>\n",
    "3B. (10pts) <b>Detect </b>faces(or pedestrians) on the first frame and draw a <b>blue</b> rectangle around your detection.<br>\n",
    "3C. (10pts) <b>Track </b>faces(or pedestrians) on subsequent frames and draw a <b>green</b> rectangle around your tracking.<br>\n",
    "3D. (<u>10pts bonus</u>) Try to find out the fastest character, draw a <b>red</b> rectangle around the fastest character, and show the output images in the <b>\"find_the_fastest_character\"</b> window.<br><br>\n",
    "\n",
    "4A. Input images from video file WiiPlay.mp4 with level 6 (frame number between 1650 and 1800).<br>\n",
    "4B. (10pts) Compute and show <b>optical flows</b> on each frame using <b>blue</b> arrows.<br>\n",
    "4C. (<u>10pts bonus</u>) Try to detect two odd character who face the opposite direction from everyone else, draw a <b>red</b> rectangle around each of the two character, and show the output images in the <b>\"find_two_odds\"</b> window.<br><br>\n",
    "\n",
    "5. (10pts) Any comments regarding the final exam? Which steps you believe you have completed? Which steps bother you?<br>\n",
    "6. (5pts) Any suggestion to teaching assistants to improve this class?<br>\n",
    "7. (5pts) Any suggestion to teacher to improve this class?<br>\n",
    "8. Upload your Jupyter code file (*.ipynb). The submission deadline is <b>midnight on 1/8</b>.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "5a. For <b>\"find_this_mii\"</b>, I completed all of it and I think that the template selection is critical to the detection, so please select the template again if the result is not satisfying.\n",
    "\n",
    "5b. For <b>\"find_two_look_alike\"</b>, I detected the pedestrians and the faces, however it is difficult to accurately detect all faces as the training dataset only includes human faces not cartoonish faces. Therefore, I have to tweak the scaleFactor and minNeighbors of face_cascade.detectMultiScale to a very low threshold, which invited some unwanted results such as false positive of the road surface. This in turn affects my template matching of look alike faces as I use the detected faces as my face templates. Therefore, I implemented face detection with 2 different criteria. To detect faces for face templates, I added hsv skin colour threshold to compensate the low threshold of face_cascade.detectMultiScale and remove unwanted false positives. Then, I do face detection again but with weaker criteria and the detection results are in light blue boxes.\n",
    "\n",
    "5c. For <b>\"find_the_fastest_character\"</b>, I completed all the steps, I chose pedestrians detection instead of faces and the reason is as stated above. Still, not all pedestrains are detected even with a low threshold. MedianFlow tracking is used to track them and I've successfully captured the fastest moving mii.\n",
    "\n",
    "5d. For <b>\"find_two_odds\"</b>, I calculated the optical flows densely to improve my turning direction detection result but the side effect is that the program runs slowly. I try to detect the odd miis using optical flow vectors but the information on the target faces is only available when turning head, so the detection of odd miis only happens during that short time period. I thought of using the positions of eyes to determine the facing direction, however the eye detection algorithm doesn't work well on some cartoonish eyes. \n",
    "\n",
    "Additional: I've noticed different output results when the code is run on different computers, especially cell 2 and cell 3.\n",
    "\n",
    "6. I hope that the practices and homework are marked and checked as soon as possible. Also, I think that it is better to write the deadline more accurately like before midnight instead of before 5pm to prevent confusion? I thought teacher said that the uploads are still counted as long as it is submitted during that day.\n",
    "\n",
    "7. The practices and homework are great for understanding the usage of different techniques in computer vision, however some students who are weak in programming, especially those who only learn about Python in the class are struggling to come up with their own program code. My suggestion is that after the submission deadline of practices or homework, can there be a basic sample code about the practices or homework for reference? So that the students have an idea about the code implementation, this may better prepare them for the exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
